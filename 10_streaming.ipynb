{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic: str\n",
    "    joke: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refin_topic(state: State):\n",
    "    return {\"topic\": state[\"topic\"] + \" and cats\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: State):\n",
    "    return {\"joke\": f\"This is a joke about {state['topic']}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = (\n",
    "    StateGraph(State).add_node(refin_topic).add_node(generate_joke).add_edge(START, \"refin_topic\").add_edge(\"refin_topic\", \"generate_joke\")\n",
    ").compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'ice cream'}\n",
      "{'topic': 'ice cream and cats'}\n",
      "{'topic': 'ice cream and cats', 'joke': 'This is a joke about ice cream and cats'}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode = \"values\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'refin_topic': {'topic': 'ice cream and cats'}}\n",
      "{'generate_joke': {'joke': 'This is a joke about ice cream and cats'}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode = \"updates\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'task', 'timestamp': '2025-02-24T06:11:39.245882+00:00', 'step': 1, 'payload': {'id': 'b9845c79-01d7-bdc5-f08f-99924c658e44', 'name': 'refin_topic', 'input': {'topic': 'ice cream'}, 'triggers': ['start:refin_topic']}}\n",
      "{'type': 'task_result', 'timestamp': '2025-02-24T06:11:39.246389+00:00', 'step': 1, 'payload': {'id': 'b9845c79-01d7-bdc5-f08f-99924c658e44', 'name': 'refin_topic', 'error': None, 'result': [('topic', 'ice cream and cats')], 'interrupts': []}}\n",
      "{'type': 'task', 'timestamp': '2025-02-24T06:11:39.246718+00:00', 'step': 2, 'payload': {'id': 'c0ab5231-5023-6056-36bb-60834ea47245', 'name': 'generate_joke', 'input': {'topic': 'ice cream and cats'}, 'triggers': ['refin_topic']}}\n",
      "{'type': 'task_result', 'timestamp': '2025-02-24T06:11:39.247014+00:00', 'step': 2, 'payload': {'id': 'c0ab5231-5023-6056-36bb-60834ea47245', 'name': 'generate_joke', 'error': None, 'result': [('joke', 'This is a joke about ice cream and cats')], 'interrupts': []}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode = \"debug\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'topic': 'ice cream'})\n",
      "('debug', {'type': 'task', 'timestamp': '2025-02-24T06:12:07.288044+00:00', 'step': 1, 'payload': {'id': '8af0535c-ffd7-18fe-bc4e-eaeccf224582', 'name': 'refin_topic', 'input': {'topic': 'ice cream'}, 'triggers': ['start:refin_topic']}})\n",
      "('updates', {'refin_topic': {'topic': 'ice cream and cats'}})\n",
      "('debug', {'type': 'task_result', 'timestamp': '2025-02-24T06:12:07.288904+00:00', 'step': 1, 'payload': {'id': '8af0535c-ffd7-18fe-bc4e-eaeccf224582', 'name': 'refin_topic', 'error': None, 'result': [('topic', 'ice cream and cats')], 'interrupts': []}})\n",
      "('values', {'topic': 'ice cream and cats'})\n",
      "('debug', {'type': 'task', 'timestamp': '2025-02-24T06:12:07.289258+00:00', 'step': 2, 'payload': {'id': '874c8e97-7183-c3b6-3301-898ab671f34f', 'name': 'generate_joke', 'input': {'topic': 'ice cream and cats'}, 'triggers': ['refin_topic']}})\n",
      "('updates', {'generate_joke': {'joke': 'This is a joke about ice cream and cats'}})\n",
      "('debug', {'type': 'task_result', 'timestamp': '2025-02-24T06:12:07.289658+00:00', 'step': 2, 'payload': {'id': '874c8e97-7183-c3b6-3301-898ab671f34f', 'name': 'generate_joke', 'error': None, 'result': [('joke', 'This is a joke about ice cream and cats')], 'interrupts': []}})\n",
      "('values', {'topic': 'ice cream and cats', 'joke': 'This is a joke about ice cream and cats'})\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode = [\"debug\",\"values\",\"updates\"]\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: State):\n",
    "    llm_response = llm.invoke(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\", \"content\": f\"Generate a joke about {state['topic']}\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return {\"joke\": llm_response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1141c3cd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(State)\n",
    "graph.add_node(refin_topic)\n",
    "graph.add_node(generate_joke)\n",
    "graph.add_edge(START, \"refin_topic\")\n",
    "graph.add_edge('refin_topic', \"generate_joke\")\n",
    "graph.add_edge(\"generate_joke\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why| did| the| cat| sit| on| the| ice| cream| cone|?\n",
      "\n",
      "|Because| it| wanted| to| be| a| little| \"|p|urr|-f|ect|\"| scoop|!| üç¶|üò∏|"
     ]
    }
   ],
   "source": [
    "for message_chunk, metadata  in graph.stream(\n",
    "    {\"topic\": \"ice cream\"},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    if message_chunk.content:\n",
    "        print(message_chunk.content, end=\"|\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import StreamWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: State, writer: StreamWriter):\n",
    "    writer({\"custom key\": \"This  a custom stream data\"})\n",
    "    return {\"joke\": f\"This is a joke about {state['topic']}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x114270790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(State)\n",
    "graph.add_node(refin_topic)\n",
    "graph.add_node(generate_joke)\n",
    "graph.add_edge(START, \"refin_topic\")\n",
    "graph.add_edge('refin_topic', \"generate_joke\")\n",
    "graph.add_edge(\"generate_joke\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom key': 'This  a custom stream data'}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\n",
    "    \"topic\": \"ice cream\"\n",
    "},\n",
    "stream_mode=\"custom\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
